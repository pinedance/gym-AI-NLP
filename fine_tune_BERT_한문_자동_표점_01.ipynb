{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPjsS0um1PRxUuqDPUPIN4O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pinedance/gym-AI-NLP/blob/main/fine_tune_BERT_%ED%95%9C%EB%AC%B8_%EC%9E%90%EB%8F%99_%ED%91%9C%EC%A0%90_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 고문헌 자동 표점 테스트\n",
        "\n",
        "source\n",
        "* [raynardj/classical-chinese-punctuation-guwen-biaodian](https://huggingface.co/raynardj/classical-chinese-punctuation-guwen-biaodian)\n",
        "\n",
        "REF\n",
        "* [BertForTokenClassification](https://huggingface.co/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification)\n",
        "* [Custom_Named_Entity_Recognition_with_BERT.ipynb](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/BERT/Custom_Named_Entity_Recognition_with_BERT.ipynb)"
      ],
      "metadata": {
        "id": "P4G_VWuXV5h2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages"
      ],
      "metadata": {
        "id": "DO9_YuOl7m0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# pip install transformers\n",
        "pip install seqeval[gpu]"
      ],
      "metadata": {
        "id": "mwboXUWRUH84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9cb0657-1fb1-47aa-a655-538846351e2c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seqeval[gpu] in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval[gpu]) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval[gpu]) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (3.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RCvoXaLyT68s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForTokenClassification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "id": "qCb2qZbUsIIV",
        "outputId": "9a1c65d9-0887-4265-c448-e9dfe3c34fdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the model"
      ],
      "metadata": {
        "id": "8WzIpJs_9HIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"raynardj/classical-chinese-punctuation-guwen-biaodian\"\n",
        "tokenizer = AutoTokenizer.from_pretrained( model_name )\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "config = AutoConfig.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "_ya6tebqU1QK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff25148-adfa-44b9-c1e1-b5e7e6f88583"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing the data"
      ],
      "metadata": {
        "id": "PEGdcLiK70Ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = [\"O\", \"，\", \"。\"]\n",
        "label2id = config.label2id\n",
        "id2label = config.id2label\n",
        "label2id"
      ],
      "metadata": {
        "id": "-vB1T0HMn72X",
        "outputId": "676d6938-be4a-480d-f08e-109558ffa48e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\"': 14,\n",
              " \"'\": 10,\n",
              " 'O': 0,\n",
              " '。': 1,\n",
              " '【': 19,\n",
              " '】': 20,\n",
              " '！': 6,\n",
              " '（': 15,\n",
              " '）': 16,\n",
              " '，': 2,\n",
              " '：': 3,\n",
              " '；': 4,\n",
              " '？': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text( text ):\n",
        "    _text = text + \"\"\n",
        "    _text = _text.replace( \",\", \"，\" )\n",
        "    _text = _text.replace( \".\", \"。\" )\n",
        "    _text = _text.replace(\" \", \"\")\n",
        "    return _text.strip()\n"
      ],
      "metadata": {
        "id": "8NUsKGjoeTCa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text_to_src_tgt( text ):\n",
        "    _text_list = list()\n",
        "    for t in text:\n",
        "        if t in [\"，\", \"。\"]:\n",
        "            _text_list.append(t)\n",
        "        else:\n",
        "            _text_list.append( t )\n",
        "            _text_list.append( \"O\")\n",
        "\n",
        "    raw_text_new = \"\".join(_text_list)\n",
        "    raw_text_new = raw_text_new.replace(\"O，\", \"，\")\n",
        "    raw_text_new = raw_text_new.replace(\"O。\", \"。\")\n",
        "\n",
        "    src, tgt = list(), list()\n",
        "    for i, c in enumerate( raw_text_new):\n",
        "        if i % 2 == 0:\n",
        "            src.append( c )\n",
        "        else:\n",
        "            tgt.append( c )\n",
        "    return \"\".join( src ), \"\".join( tgt )\n"
      ],
      "metadata": {
        "id": "7lUOXf5Bex55"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_inputs = [\n",
        "    \"風寒暑, 暴傷人便覺, 濕氣熏襲, 人多不覺. 其自外而入者, 長夏鬱熱, 山澤蒸氣, 冒雨行濕, 汗透沾衣. 多腰脚腫痛. 其自內得者, 生冷酒麪滯, 脾生濕, 鬱熱, 多肚腹腫脹. 西北人, 多內濕, 東南人, 多外濕.\",\n",
        "    \"人居戴履, 受濕最多. 行住坐臥, 實熏染於冥冥之中, 滯而爲喘嗽, 漬而爲嘔吐, 滲而爲泄瀉, 溢而爲浮腫. 濕瘀熱則發黃, 濕遍體則重着, 濕入關節則一身盡痛, 濕聚痰涎則昏不知人.\",\n",
        "    \"濕家治法, 大槪宜發微汗, 及利小便, 使上下分消其濕, 是其治也.\",\n",
        "    \"濕上甚而熱, 治以苦溫, 佐以甘辛, 以汗爲故而止, 平胃散方見內傷主之. 濕在上, 宜微汗而解, 不欲汗多, 故不用麻黃ㆍ乾葛輩. 宜微汗, 用防己黃芪湯.\",\n",
        "    \"濕在中下, 宜利小便, 此淡滲治濕也. 五苓散主之.\",\n",
        "    \"凡濕病, 忌不得以火攻幷轉利之. 若濕家下之, 則額上汗出, 微喘, 小便不利者, 死, 下利不止者亦, 死.\",\n",
        "    \"治濕不得猛發汗, 及灼艾灸之.\",\n",
        "    \"濕病誤下, 則爲喘噦, 誤汗, 則發痓而死.\",\n",
        "    \"濕家不可汗, 汗之則發痓, 發痓者斃. 又不可下, 下之則額汗胸滿, 微喘而噦, 小便淋閉, 難以有瘳也.\",\n",
        "    \"太陽病, 發汗太多, 因致痓. 濕家大發汗, 亦作痓. 盖汗太多則亡陽, 不能養筋, 故筋脉緊急而成痓. 其證身熱足冷, 頸項强急, 惡寒, 時頭熱, 面赤目赤, 獨頭面搖, 卒口噤, 背反張者, 是也. 亦名破傷風.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "YbieD__fVMV0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_cleaned = [ clean_text(text) for text in new_inputs ]\n",
        "text_cleaned"
      ],
      "metadata": {
        "id": "Qfs7gu-pg8n1",
        "outputId": "9220a550-5b35-4620-f9c0-f815a61816d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['風寒暑，暴傷人便覺，濕氣熏襲，人多不覺。其自外而入者，長夏鬱熱，山澤蒸氣，冒雨行濕，汗透沾衣。多腰脚腫痛。其自內得者，生冷酒麪滯，脾生濕，鬱熱，多肚腹腫脹。西北人，多內濕，東南人，多外濕。',\n",
              " '人居戴履，受濕最多。行住坐臥，實熏染於冥冥之中，滯而爲喘嗽，漬而爲嘔吐，滲而爲泄瀉，溢而爲浮腫。濕瘀熱則發黃，濕遍體則重着，濕入關節則一身盡痛，濕聚痰涎則昏不知人。',\n",
              " '濕家治法，大槪宜發微汗，及利小便，使上下分消其濕，是其治也。',\n",
              " '濕上甚而熱，治以苦溫，佐以甘辛，以汗爲故而止，平胃散方見內傷主之。濕在上，宜微汗而解，不欲汗多，故不用麻黃ㆍ乾葛輩。宜微汗，用防己黃芪湯。',\n",
              " '濕在中下，宜利小便，此淡滲治濕也。五苓散主之。',\n",
              " '凡濕病，忌不得以火攻幷轉利之。若濕家下之，則額上汗出，微喘，小便不利者，死，下利不止者亦，死。',\n",
              " '治濕不得猛發汗，及灼艾灸之。',\n",
              " '濕病誤下，則爲喘噦，誤汗，則發痓而死。',\n",
              " '濕家不可汗，汗之則發痓，發痓者斃。又不可下，下之則額汗胸滿，微喘而噦，小便淋閉，難以有瘳也。',\n",
              " '太陽病，發汗太多，因致痓。濕家大發汗，亦作痓。盖汗太多則亡陽，不能養筋，故筋脉緊急而成痓。其證身熱足冷，頸項强急，惡寒，時頭熱，面赤目赤，獨頭面搖，卒口噤，背反張者，是也。亦名破傷風。']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_text, tgt_text = list( zip( *[ split_text_to_src_tgt( text) for text in text_cleaned ] ) )"
      ],
      "metadata": {
        "id": "Iz4m5FHIhLKU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_text"
      ],
      "metadata": {
        "id": "pZHFhvB8jMG9",
        "outputId": "8dc04b3a-f2b8-48bc-f1ed-40c0d7fd4120",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('風寒暑暴傷人便覺濕氣熏襲人多不覺其自外而入者長夏鬱熱山澤蒸氣冒雨行濕汗透沾衣多腰脚腫痛其自內得者生冷酒麪滯脾生濕鬱熱多肚腹腫脹西北人多內濕東南人多外濕',\n",
              " '人居戴履受濕最多行住坐臥實熏染於冥冥之中滯而爲喘嗽漬而爲嘔吐滲而爲泄瀉溢而爲浮腫濕瘀熱則發黃濕遍體則重着濕入關節則一身盡痛濕聚痰涎則昏不知人',\n",
              " '濕家治法大槪宜發微汗及利小便使上下分消其濕是其治也',\n",
              " '濕上甚而熱治以苦溫佐以甘辛以汗爲故而止平胃散方見內傷主之濕在上宜微汗而解不欲汗多故不用麻黃ㆍ乾葛輩宜微汗用防己黃芪湯',\n",
              " '濕在中下宜利小便此淡滲治濕也五苓散主之',\n",
              " '凡濕病忌不得以火攻幷轉利之若濕家下之則額上汗出微喘小便不利者死下利不止者亦死',\n",
              " '治濕不得猛發汗及灼艾灸之',\n",
              " '濕病誤下則爲喘噦誤汗則發痓而死',\n",
              " '濕家不可汗汗之則發痓發痓者斃又不可下下之則額汗胸滿微喘而噦小便淋閉難以有瘳也',\n",
              " '太陽病發汗太多因致痓濕家大發汗亦作痓盖汗太多則亡陽不能養筋故筋脉緊急而成痓其證身熱足冷頸項强急惡寒時頭熱面赤目赤獨頭面搖卒口噤背反張者是也亦名破傷風')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tgt_text"
      ],
      "metadata": {
        "id": "KjUI-XtGjl3O",
        "outputId": "03eaa5c7-5695-47da-a140-d87e381c2eed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('OO，OOOO，OOO，OOO。OOOOO，OOO，OOO，OOO，OOO。OOOO。OOOO，OOOO，OO，O，OOOO。OO，OO，OO，OO。',\n",
              " 'OOO，OOO。OOO，OOOOOOO，OOOO，OOOO，OOOO，OOOO。OOOOO，OOOOO，OOOOOOOO，OOOOOOOO。',\n",
              " 'OOO，OOOOO，OOO，OOOOOO，OOO。',\n",
              " 'OOOO，OOO，OOO，OOOOO，OOOOOOOO。OO，OOOO，OOO，OOOOOOOO。OO，OOOOO。',\n",
              " 'OOO，OOO，OOOOO。OOOO。',\n",
              " 'OO，OOOOOOOOO。OOOO，OOOO，O，OOOO，，OOOOO，。',\n",
              " 'OOOOOO，OOOO。',\n",
              " 'OOO，OOO，O，OOOO。',\n",
              " 'OOOO，OOOO，OOO。OOO，OOOOOO，OOO，OOO，OOOO。',\n",
              " 'OO，OOO，OO。OOOO，OO。OOOOOO，OOO，OOOOOOO。OOOOO，OOO，O，OO，OOO，OOO，OO，OOO，O。OOOO。')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( [ len(e) for e in src_text], [len(e) for e in tgt_text ])"
      ],
      "metadata": {
        "id": "NgAldDh1lsAO",
        "outputId": "8773431d-61fd-45bc-bd68-1e46109cd611",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[75, 70, 25, 58, 19, 38, 12, 15, 38, 74] [75, 70, 25, 58, 19, 38, 12, 15, 38, 74]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame( {\"sentence\": src_text, \"word_labels\": tgt_text} ).drop_duplicates().reset_index(drop=True)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "Rk7oz8hglUNb",
        "outputId": "3e354348-b75b-4666-bc04-d6f478242e57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  風寒暑暴傷人便覺濕氣熏襲人多不覺其自外而入者長夏鬱熱山澤蒸氣冒雨行濕汗透沾衣多腰脚腫痛其自內...   \n",
              "1  人居戴履受濕最多行住坐臥實熏染於冥冥之中滯而爲喘嗽漬而爲嘔吐滲而爲泄瀉溢而爲浮腫濕瘀熱則發黃...   \n",
              "2                          濕家治法大槪宜發微汗及利小便使上下分消其濕是其治也   \n",
              "3  濕上甚而熱治以苦溫佐以甘辛以汗爲故而止平胃散方見內傷主之濕在上宜微汗而解不欲汗多故不用麻黃ㆍ...   \n",
              "4                                濕在中下宜利小便此淡滲治濕也五苓散主之   \n",
              "\n",
              "                                         word_labels  \n",
              "0  OO，OOOO，OOO，OOO。OOOOO，OOO，OOO，OOO，OOO。OOOO。OOO...  \n",
              "1  OOO，OOO。OOO，OOOOOOO，OOOO，OOOO，OOOO，OOOO。OOOOO，...  \n",
              "2                          OOO，OOOOO，OOO，OOOOOO，OOO。  \n",
              "3  OOOO，OOO，OOO，OOOOO，OOOOOOOO。OO，OOOO，OOO，OOOOOO...  \n",
              "4                                OOO，OOO，OOOOO。OOOO。  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00e606b2-0e36-456b-b322-c85aa366580b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>風寒暑暴傷人便覺濕氣熏襲人多不覺其自外而入者長夏鬱熱山澤蒸氣冒雨行濕汗透沾衣多腰脚腫痛其自內...</td>\n",
              "      <td>OO，OOOO，OOO，OOO。OOOOO，OOO，OOO，OOO，OOO。OOOO。OOO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>人居戴履受濕最多行住坐臥實熏染於冥冥之中滯而爲喘嗽漬而爲嘔吐滲而爲泄瀉溢而爲浮腫濕瘀熱則發黃...</td>\n",
              "      <td>OOO，OOO。OOO，OOOOOOO，OOOO，OOOO，OOOO，OOOO。OOOOO，...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>濕家治法大槪宜發微汗及利小便使上下分消其濕是其治也</td>\n",
              "      <td>OOO，OOOOO，OOO，OOOOOO，OOO。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>濕上甚而熱治以苦溫佐以甘辛以汗爲故而止平胃散方見內傷主之濕在上宜微汗而解不欲汗多故不用麻黃ㆍ...</td>\n",
              "      <td>OOOO，OOO，OOO，OOOOO，OOOOOOOO。OO，OOOO，OOO，OOOOOO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>濕在中下宜利小便此淡滲治濕也五苓散主之</td>\n",
              "      <td>OOO，OOO，OOOOO。OOOO。</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00e606b2-0e36-456b-b322-c85aa366580b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-00e606b2-0e36-456b-b322-c85aa366580b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-00e606b2-0e36-456b-b322-c85aa366580b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a91225e0-695d-4123-bf60-c0fa1f81f0ff\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a91225e0-695d-4123-bf60-c0fa1f81f0ff')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a91225e0-695d-4123-bf60-c0fa1f81f0ff button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\u6fd5\\u5bb6\\u4e0d\\u53ef\\u6c57\\u6c57\\u4e4b\\u5247\\u767c\\u75d3\\u767c\\u75d3\\u8005\\u6583\\u53c8\\u4e0d\\u53ef\\u4e0b\\u4e0b\\u4e4b\\u5247\\u984d\\u6c57\\u80f8\\u6eff\\u5fae\\u5598\\u800c\\u5666\\u5c0f\\u4fbf\\u6dcb\\u9589\\u96e3\\u4ee5\\u6709\\u7633\\u4e5f\",\n          \"\\u4eba\\u5c45\\u6234\\u5c65\\u53d7\\u6fd5\\u6700\\u591a\\u884c\\u4f4f\\u5750\\u81e5\\u5be6\\u718f\\u67d3\\u65bc\\u51a5\\u51a5\\u4e4b\\u4e2d\\u6eef\\u800c\\u7232\\u5598\\u55fd\\u6f2c\\u800c\\u7232\\u5614\\u5410\\u6ef2\\u800c\\u7232\\u6cc4\\u7009\\u6ea2\\u800c\\u7232\\u6d6e\\u816b\\u6fd5\\u7600\\u71b1\\u5247\\u767c\\u9ec3\\u6fd5\\u904d\\u9ad4\\u5247\\u91cd\\u7740\\u6fd5\\u5165\\u95dc\\u7bc0\\u5247\\u4e00\\u8eab\\u76e1\\u75db\\u6fd5\\u805a\\u75f0\\u6d8e\\u5247\\u660f\\u4e0d\\u77e5\\u4eba\",\n          \"\\u51e1\\u6fd5\\u75c5\\u5fcc\\u4e0d\\u5f97\\u4ee5\\u706b\\u653b\\u5e77\\u8f49\\u5229\\u4e4b\\u82e5\\u6fd5\\u5bb6\\u4e0b\\u4e4b\\u5247\\u984d\\u4e0a\\u6c57\\u51fa\\u5fae\\u5598\\u5c0f\\u4fbf\\u4e0d\\u5229\\u8005\\u6b7b\\u4e0b\\u5229\\u4e0d\\u6b62\\u8005\\u4ea6\\u6b7b\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_labels\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"OOOO\\uff0cOOOO\\uff0cOOO\\u3002OOO\\uff0cOOOOOO\\uff0cOOO\\uff0cOOO\\uff0cOOOO\\u3002\",\n          \"OOO\\uff0cOOO\\u3002OOO\\uff0cOOOOOOO\\uff0cOOOO\\uff0cOOOO\\uff0cOOOO\\uff0cOOOO\\u3002OOOOO\\uff0cOOOOO\\uff0cOOOOOOOO\\uff0cOOOOOOOO\\u3002\",\n          \"OO\\uff0cOOOOOOOOO\\u3002OOOO\\uff0cOOOO\\uff0cO\\uff0cOOOO\\uff0c\\uff0cOOOOO\\uff0c\\u3002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the dataset and dataloader"
      ],
      "metadata": {
        "id": "g44PjcGs8KV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 1e-05\n",
        "MAX_GRAD_NORM = 10"
      ],
      "metadata": {
        "id": "i9LCs9zlpMgU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "\n",
        "    # tokenized_sentence = []\n",
        "    # labels = []\n",
        "\n",
        "    # sentence = sentence.strip()\n",
        "\n",
        "    # for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
        "\n",
        "    #     # Tokenize the word and count # of subwords the word is broken into\n",
        "    #     tokenized_word = tokenizer.tokenize(word)\n",
        "    #     n_subwords = len(tokenized_word)\n",
        "\n",
        "    #     # Add the tokenized word to the final tokenized word list\n",
        "    #     tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "    #     # Add the same label to the new list of labels `n_subwords` times\n",
        "    #     labels.extend([label] * n_subwords)\n",
        "\n",
        "    tokenized_sentence = tokenizer.tokenize( sentence.strip() )\n",
        "    labels = list( text_labels.strip() )\n",
        "    if len( tokenized_sentence ) != len(labels ):\n",
        "        print(\"!!! length of sentence and labels miss match !!!\", len( tokenized_sentence ), len(labels ) )\n",
        "    return tokenized_sentence, labels\n"
      ],
      "metadata": {
        "id": "cnJOn9vV4tdR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: tokenize (and adapt corresponding labels)\n",
        "        sentence = self.data.sentence[index]\n",
        "        word_labels = self.data.word_labels[index]\n",
        "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
        "\n",
        "        # step 2: add special tokens (and corresponding labels)\n",
        "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
        "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
        "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
        "\n",
        "        # step 3: truncating/padding\n",
        "        maxlen = self.max_len\n",
        "\n",
        "        if (len(tokenized_sentence) > maxlen):\n",
        "          # truncate\n",
        "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
        "          labels = labels[:maxlen]\n",
        "        else:\n",
        "          # pad\n",
        "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
        "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
        "\n",
        "        # step 4: obtain the attention mask\n",
        "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
        "\n",
        "        # step 5: convert tokens to input ids\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "\n",
        "        label_ids = [label2id[label] for label in labels]\n",
        "        # the following line is deprecated\n",
        "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
        "\n",
        "        return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
        "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "TA8xnp72l2oL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 0.8\n",
        "train_dataset = data.sample(frac=train_size,random_state=200)\n",
        "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(data.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
        "training_set = dataset(data, tokenizer, MAX_LEN )"
      ],
      "metadata": {
        "id": "bFTNywX8VYeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aa5fe2f-d8de-49af-9cc7-503ca43761df"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (10, 2)\n",
            "TRAIN Dataset: (8, 2)\n",
            "TEST Dataset: (2, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set[0]"
      ],
      "metadata": {
        "id": "QX4NJJghb2ky",
        "outputId": "51d165b9-8d9a-4708-821f-da9b2340c26d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': tensor([ 101, 7591, 2170, 3264, 3274, 1003,  782,  912, 6221, 4086, 3706, 4221,\n",
              "         6204,  782, 1914,  679, 6221, 1071, 5632, 1912, 5445, 1057, 5442, 7269,\n",
              "         1909, 7786, 4229, 2255, 4075, 5892, 3706, 1088, 7433, 6121, 4086, 3731,\n",
              "         6851, 3783, 6132, 1914, 5587, 5558, 5584, 4578, 1071, 5632, 1058, 2533,\n",
              "         5442, 4495, 1107, 6983,  100, 4015, 5569, 4495, 4086, 7786, 4229, 1914,\n",
              "         5496, 5592, 5584, 5568, 6205, 1266,  782, 1914, 1058, 4086, 3346, 1298,\n",
              "          782, 1914, 1912, 4086,  102,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0]),\n",
              " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'targets': tensor([0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0,\n",
              "         0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "         2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 2, 0, 0,\n",
              "         2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0])}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set[0][\"ids\"]"
      ],
      "metadata": {
        "id": "OwFM0a8frwEB",
        "outputId": "c2e50b97-31bf-4a45-b234-8626d8a284e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 101, 7591, 2170, 3264, 3274, 1003,  782,  912, 6221, 4086, 3706, 4221,\n",
              "        6204,  782, 1914,  679, 6221, 1071, 5632, 1912, 5445, 1057, 5442, 7269,\n",
              "        1909, 7786, 4229, 2255, 4075, 5892, 3706, 1088, 7433, 6121, 4086, 3731,\n",
              "        6851, 3783, 6132, 1914, 5587, 5558, 5584, 4578, 1071, 5632, 1058, 2533,\n",
              "        5442, 4495, 1107, 6983,  100, 4015, 5569, 4495, 4086, 7786, 4229, 1914,\n",
              "        5496, 5592, 5584, 5568, 6205, 1266,  782, 1914, 1058, 4086, 3346, 1298,\n",
              "         782, 1914, 1912, 4086,  102,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "metadata": {
        "id": "lz58PNvdVgty"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model"
      ],
      "metadata": {
        "id": "RUkruRwq8f9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "id": "q8fcKiCXr-d1",
        "outputId": "874762b1-4a1c-4913-9f5f-ae2df52ea005",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=21, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(0)\n"
      ],
      "metadata": {
        "id": "o9TmuQT3VtIm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n"
      ],
      "metadata": {
        "id": "JmDcvEDJ6cCm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwXo2d046dlc",
        "outputId": "4e60ef6c-f757-4635-b21f-c084860c6e3d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6591, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_logits = outputs[1]\n",
        "tr_logits.shape"
      ],
      "metadata": {
        "id": "17e8v4M_saR2",
        "outputId": "96b0e4c7-b387-4d6c-eaa5-8c2d86b0f138",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512, 21])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "CDLakGXhVm5N"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "\n",
        "    for idx, batch in enumerate(training_loader):\n",
        "\n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "        loss, tr_logits = outputs.loss, outputs.logits\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "\n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
        "\n",
        "        # compute training accuracy\n",
        "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        tr_preds.extend(predictions)\n",
        "        tr_labels.extend(targets)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
      ],
      "metadata": {
        "id": "rnw6sQ0tsfJd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ],
      "metadata": {
        "id": "0Db18EblsfLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dc0153f-057e-4e68-d983-da25ece644a2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "Training loss per 100 training steps: 0.6868448853492737\n",
            "Training loss epoch: 0.41577161848545074\n",
            "Training accuracy epoch: 0.8426655777017631\n",
            "Training epoch: 2\n",
            "Training loss per 100 training steps: 0.11325179785490036\n",
            "Training loss epoch: 0.10659048209587733\n",
            "Training accuracy epoch: 0.8210687983191152\n",
            "Training epoch: 3\n",
            "Training loss per 100 training steps: 0.03695332631468773\n",
            "Training loss epoch: 0.06341010704636574\n",
            "Training accuracy epoch: 0.8227616250515148\n",
            "Training epoch: 4\n",
            "Training loss per 100 training steps: 0.03784318268299103\n",
            "Training loss epoch: 0.050183908392985664\n",
            "Training accuracy epoch: 0.8291351108344571\n",
            "Training epoch: 5\n",
            "Training loss per 100 training steps: 0.05637424811720848\n",
            "Training loss epoch: 0.04743218546112379\n",
            "Training accuracy epoch: 0.8281718144484933\n",
            "Training epoch: 6\n",
            "Training loss per 100 training steps: 0.05674177408218384\n",
            "Training loss epoch: 0.05269674708445867\n",
            "Training accuracy epoch: 0.8245806325530275\n",
            "Training epoch: 7\n",
            "Training loss per 100 training steps: 0.01897936500608921\n",
            "Training loss epoch: 0.04368260440727075\n",
            "Training accuracy epoch: 0.82802890310353\n",
            "Training epoch: 8\n",
            "Training loss per 100 training steps: 0.03986946865916252\n",
            "Training loss epoch: 0.04202121372024218\n",
            "Training accuracy epoch: 0.833885386728863\n",
            "Training epoch: 9\n",
            "Training loss per 100 training steps: 0.04641957953572273\n",
            "Training loss epoch: 0.03551937732845545\n",
            "Training accuracy epoch: 0.8707027730218454\n",
            "Training epoch: 10\n",
            "Training loss per 100 training steps: 0.032243818044662476\n",
            "Training loss epoch: 0.03075265201429526\n",
            "Training accuracy epoch: 0.8641812571470765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the model"
      ],
      "metadata": {
        "id": "oSG4FyS29VJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "\n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "            loss, eval_logits = outputs.loss, outputs.logits\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += targets.size(0)\n",
        "\n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
        "\n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "\n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    #print(eval_labels)\n",
        "    #print(eval_preds)\n",
        "\n",
        "    labels = [id2label[id.item()] for id in eval_labels]\n",
        "    predictions = [id2label[id.item()] for id in eval_preds]\n",
        "\n",
        "    #print(labels)\n",
        "    #print(predictions)\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "\n",
        "    return labels, predictions"
      ],
      "metadata": {
        "id": "4ciWaHOwsfOK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels, predictions = valid(model, testing_loader)"
      ],
      "metadata": {
        "id": "BQUkBIxJsfQw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8290599-74fe-4f1e-fb01-d12696ec0276"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss per 100 evaluation steps: 0.04806925356388092\n",
            "Validation Loss: 0.04806925356388092\n",
            "Validation Accuracy: 0.8758169934640523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from seqeval.metrics import classification_report\n",
        "\n",
        "# print(classification_report([labels], [predictions]))"
      ],
      "metadata": {
        "id": "Dr0aOKXuaz6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "gEAsNChu9ZhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"濕上甚而熱治以苦溫佐以甘辛以汗爲故而止平胃散方見內傷主之濕在上宜微汗而解不欲汗多故不用麻黃乾葛輩宜微汗用防己黃芪湯\"\n",
        "\n",
        "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
        "\n",
        "# move to gpu\n",
        "ids = inputs[\"input_ids\"].to(device)\n",
        "mask = inputs[\"attention_mask\"].to(device)\n",
        "# forward pass\n",
        "outputs = model(ids, mask)\n",
        "logits = outputs[0]\n",
        "\n",
        "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
        "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
        "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
        "\n",
        "word_level_predictions = []\n",
        "for pair in wp_preds:\n",
        "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
        "    # skip prediction\n",
        "    continue\n",
        "  else:\n",
        "    word_level_predictions.append(pair[1])\n",
        "\n",
        "# we join tokens, if they are not special ones\n",
        "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
        "print(str_rep)\n",
        "print(word_level_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLQBEXuZWPHG",
        "outputId": "6acb7de9-b9ec-4499-de29-5a7bde0e9af8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "濕 上 甚 而 熱 治 以 苦 溫 佐 以 甘 辛 以 汗 爲 故 而 止 平 胃 散 方 見 內 傷 主 之 濕 在 上 宜 微 汗 而 解 不 欲 汗 多 故 不 用 麻 黃 乾 葛 輩 宜 微 汗 用 防 己 黃 芪 湯\n",
            "['O', 'O', 'O', 'O', '，', 'O', 'O', 'O', '，', 'O', 'O', 'O', '，', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '。', 'O', 'O', '，', 'O', 'O', 'O', 'O', '，', 'O', 'O', 'O', '，', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '，', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_output( input_text, predicted_class ):\n",
        "    if len(input_text) != len(predicted_class):\n",
        "        print( \"입력 텍스트와 결과 텍트트의 길이가 서로 다릅니다. \")\n",
        "        return None\n",
        "    output_list = list()\n",
        "    for a, b in zip( input_text, predicted_class ):\n",
        "        output_list.append( a )\n",
        "        if b != \"O\":\n",
        "            output_list.append( b )\n",
        "    rst = \"\".join( output_list )\n",
        "    rst = rst.replace(\"\", \"\")\n",
        "    return rst"
      ],
      "metadata": {
        "id": "XQ5tdcTGAfr4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "build_output( sentence, word_level_predictions )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "08FS8RVNAv2Q",
        "outputId": "6ca6c75f-551a-4896-b826-f7ef966e79cc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'濕上甚而熱，治以苦溫，佐以甘辛，以汗爲故而止平胃散方見內傷主之。濕在上，宜微汗而解，不欲汗多，故不用麻黃乾葛輩宜微汗，用防己黃芪湯'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(task=\"token-classification\", model=model.to(\"cpu\"), tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
        "sentence = \"濕上甚而熱治以苦溫佐以甘辛以汗爲故而止平胃散方見內傷主之濕在上宜微汗而解不欲汗多故不用麻黃乾葛輩宜微汗用防己黃芪湯\"\n",
        "pipe(sentence)"
      ],
      "metadata": {
        "id": "DmL25EJkXqcl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4795fb5-ab5f-46bc-ca7d-f60e0d9447c3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': '，', 'score': 0.8703088, 'word': '熱', 'start': 4, 'end': 5},\n",
              " {'entity_group': '，', 'score': 0.7995402, 'word': '溫', 'start': 8, 'end': 9},\n",
              " {'entity_group': '，',\n",
              "  'score': 0.7567696,\n",
              "  'word': '辛',\n",
              "  'start': 12,\n",
              "  'end': 13},\n",
              " {'entity_group': '。',\n",
              "  'score': 0.8064684,\n",
              "  'word': '之',\n",
              "  'start': 27,\n",
              "  'end': 28},\n",
              " {'entity_group': '，',\n",
              "  'score': 0.8801451,\n",
              "  'word': '上',\n",
              "  'start': 30,\n",
              "  'end': 31},\n",
              " {'entity_group': '，',\n",
              "  'score': 0.84420615,\n",
              "  'word': '解',\n",
              "  'start': 35,\n",
              "  'end': 36},\n",
              " {'entity_group': '，',\n",
              "  'score': 0.92889386,\n",
              "  'word': '多',\n",
              "  'start': 39,\n",
              "  'end': 40},\n",
              " {'entity_group': '，',\n",
              "  'score': 0.8986384,\n",
              "  'word': '汗',\n",
              "  'start': 50,\n",
              "  'end': 51}]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "d-puYe2AZE4d",
        "outputId": "7c912bd3-4859-469b-e63c-f0b7a9ea1bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'郡邑，置夫子庙于学，以嵗时释奠。盖自唐。贞观以来，未之或改。我宋有天下因其制而损益之。姑苏当浙右要区，规模尤大，更建炎戎马，荡然无遗。虽修学宫于荆榛瓦砾之余，独殿宇未遑议也。每春秋展礼于斋庐，已则置不问，殆为阙典。今寳文阁直学士括苍梁公来牧之。明年，实绍兴十有一禩也。二月，上丁修祀既毕，乃愓然自咎，揖诸生而告之曰\"天子不以汝嘉为不肖，俾再守兹土，顾治民事神，皆守之职。惟是夫子之祀，教化所基，尤宜严且谨。而拜跪荐祭之地，卑陋乃尔！其何以掲防妥灵？汝嘉不敢避其责。曩常去此弥年，若有所负，尚安得以罢輭自恕，复累后人乎！他日或克就绪，愿与诸君落之。于是谋之，僚吏搜故府，得遗材千枚，取赢资以给其费。鸠工庀役，各举其任。嵗月讫，工民不与知像设礼器，百用具修。至于堂室。廊序。门牖。垣墙，皆一新之。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-finetuned-ner\"\n",
        "\n",
        "# upload files to the hub\n",
        "tokenizer.push_to_hub(\n",
        "    repo_path_or_name=model_name,\n",
        "    organization=\"nielsr\",\n",
        "    commit_message=\"Add tokenizer\",\n",
        "    use_temp_dir=True,\n",
        ")\n",
        "model.push_to_hub(\n",
        "    repo_path_or_name=model_name,\n",
        "    organization=\"nielsr\",\n",
        "    commit_message=\"Add model\",\n",
        "    use_temp_dir=True,\n",
        ")"
      ],
      "metadata": {
        "id": "q9xmfgtl7Oje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "model_name = \"nielsr/bert-finetuned-ner\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "u5vBu1Ss7RLy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}