{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM6aOJfgqwpGNToDWaD8rIs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pinedance/gym-AI-NLP/blob/main/%ED%95%9C%EB%AC%B8_%EC%9E%90%EB%8F%99_%ED%91%9C%EC%A0%90_%ED%85%8C%EC%8A%A4%ED%8A%B8_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 고문헌 자동 표점 테스트\n",
        "\n",
        "source\n",
        "* [raynardj/classical-chinese-punctuation-guwen-biaodian](https://huggingface.co/raynardj/classical-chinese-punctuation-guwen-biaodian)\n",
        "\n",
        "REF\n",
        "* [BertForTokenClassification](https://huggingface.co/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification)"
      ],
      "metadata": {
        "id": "P4G_VWuXV5h2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# pip install transformers"
      ],
      "metadata": {
        "id": "mwboXUWRUH84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCvoXaLyT68s"
      },
      "outputs": [],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"raynardj/classical-chinese-punctuation-guwen-biaodian\"\n",
        "tokenizer = AutoTokenizer.from_pretrained( model_name )\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ya6tebqU1QK",
        "outputId": "afdc3efe-8f15-4f34-cdf4-935bbbd2b6f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_input = \"郡邑置夫子庙于学以嵗时释奠盖自唐贞观以来未之或改我宋有天下因其制而损益之姑苏当浙右要区规模尤大更建炎戎马荡然无遗虽修学宫于荆榛瓦砾之余独殿宇未遑议也每春秋展礼于斋庐已则置不问殆为阙典今寳文阁直学士括苍梁公来牧之明年实绍兴十有一禩也二月上丁修祀既毕乃愓然自咎揖诸生而告之曰天子不以汝嘉为不肖俾再守兹土顾治民事神皆守之职惟是夫子之祀教化所基尤宜严且谨而拜跪荐祭之地卑陋乃尔其何以掲防妥灵汝嘉不敢避其责曩常去此弥年若有所负尚安得以罢輭自恕复累后人乎他日或克就绪愿与诸君落之于是谋之僚吏搜故府得遗材千枚取赢资以给其费鸠工庀役各举其任嵗月讫工民不与知像设礼器百用具修至于堂室廊序门牖垣墙皆一新之\"\n"
      ],
      "metadata": {
        "id": "YbieD__fVMV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_input = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nHjrEZmkbQNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer( example_input, add_special_tokens=False, return_tensors=\"pt\" )"
      ],
      "metadata": {
        "id": "bFTNywX8VYeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    logits = model( **inputs ).logits"
      ],
      "metadata": {
        "id": "lz58PNvdVgty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_token_class_ids = logits.argmax(-1)"
      ],
      "metadata": {
        "id": "o9TmuQT3VtIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_tokens_classes = [model.config.id2label[t.item()] for t in predicted_token_class_ids[0]]"
      ],
      "metadata": {
        "id": "CDLakGXhVm5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list( set( predicted_tokens_classes ) )"
      ],
      "metadata": {
        "id": "Dr0aOKXuaz6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = predicted_token_class_ids\n",
        "loss = model(**inputs, labels=labels).loss\n",
        "round(loss.item(), 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLQBEXuZWPHG",
        "outputId": "24244353-0317-42ab-f695-3cc95d3aa8c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_output( input_text, predicted_class ):\n",
        "    if len(input_text) != len(predicted_class):\n",
        "        print( \"입력 텍스트와 결과 텍트트의 길이가 서로 다릅니다. \")\n",
        "        return None\n",
        "    output_list = list()\n",
        "    for a, b in zip( input_text, predicted_class ):\n",
        "        output_list.append( a )\n",
        "        if b != \"O\":\n",
        "            output_list.append( b )\n",
        "    rst = \"\".join( output_list )\n",
        "    rst = rst.replace(\"\", \"\")\n",
        "    return rst"
      ],
      "metadata": {
        "id": "DmL25EJkXqcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "build_output( example_input, predicted_tokens_classes )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "d-puYe2AZE4d",
        "outputId": "7c912bd3-4859-469b-e63c-f0b7a9ea1bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'郡邑，置夫子庙于学，以嵗时释奠。盖自唐。贞观以来，未之或改。我宋有天下因其制而损益之。姑苏当浙右要区，规模尤大，更建炎戎马，荡然无遗。虽修学宫于荆榛瓦砾之余，独殿宇未遑议也。每春秋展礼于斋庐，已则置不问，殆为阙典。今寳文阁直学士括苍梁公来牧之。明年，实绍兴十有一禩也。二月，上丁修祀既毕，乃愓然自咎，揖诸生而告之曰\"天子不以汝嘉为不肖，俾再守兹土，顾治民事神，皆守之职。惟是夫子之祀，教化所基，尤宜严且谨。而拜跪荐祭之地，卑陋乃尔！其何以掲防妥灵？汝嘉不敢避其责。曩常去此弥年，若有所负，尚安得以罢輭自恕，复累后人乎！他日或克就绪，愿与诸君落之。于是谋之，僚吏搜故府，得遗材千枚，取赢资以给其费。鸠工庀役，各举其任。嵗月讫，工民不与知像设礼器，百用具修。至于堂室。廊序。门牖。垣墙，皆一新之。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}